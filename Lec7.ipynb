{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kterashi/niigata_lecture_2024/blob/master/Lec7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum Machine Learning Applications to High-Energy Physics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Event Classfication using Quantum Neural Networks\n",
    "\n",
    "First, we consider the problem of classifying signal events from background events using kinematic features in the events, one of the most representative tasks for machine learning in HEP data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preparation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, get all the necessary libraries from the copy and import packages\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tarfile\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "shutil.copy('/content/gdrive/MyDrive/qcintro.tar.gz', '.')\n",
    "with tarfile.open('qcintro.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='/root/.local')\n",
    "\n",
    "sys.path.append('/root/.local/lib/python3.10/site-packages')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!git clone -b master https://github.com/kterashi/niigata_lecture_2024\n",
    "\n",
    "# Tested with python 3.10.11, qiskit 0.42.1, numpy 1.23.5, scipy 1.9.3\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import OrderedDict\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from qiskit.circuit.library import TwoLocal, ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.primitives import Estimator, Sampler, BackendEstimator\n",
    "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
    "from qiskit_algorithms.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit_algorithms.minimum_eigensolvers import VQE, NumPyMinimumEigensolver\n",
    "from qiskit_algorithms.optimizers import SPSA, COBYLA\n",
    "from qiskit_optimization.applications import OptimizationApplication\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Sampler as RuntimeSampler\n",
    "from qiskit_ibm_runtime.accounts import AccountNotFoundError\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T05:33:43.037732Z",
     "start_time": "2024-12-07T05:33:42.972035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "input_file = os.getcwd()+'/niigata_lecture_2024/data/SUSY_1K.csv'\n",
    "df = pd.read_csv(input_file,\n",
    "                 names=('isSignal','lep1_pt','lep1_eta','lep1_phi','lep2_pt','lep2_eta',\n",
    "                        'lep2_phi','miss_ene','miss_phi','MET_rel','axial_MET','M_R','M_TR_2',\n",
    "                        'R','MT2','S_R','M_Delta_R','dPhi_r_b','cos_theta_r1'))\n",
    "\n",
    "# Number of input features for training\n",
    "feature_dim = 3\n",
    "\n",
    "# Feature variables\n",
    "if feature_dim == 3:\n",
    "    selected_features = ['lep1_pt', 'lep2_pt', 'miss_ene']\n",
    "elif feature_dim == 5:\n",
    "    selected_features = ['lep1_pt','lep2_pt','miss_ene','M_TR_2','M_Delta_R']\n",
    "elif feature_dim == 7:\n",
    "    selected_features = ['lep1_pt','lep1_eta','lep2_pt','lep2_eta','miss_ene','M_TR_2','M_Delta_R']\n",
    "\n",
    "# Number of events used in the training and testing\n",
    "train_size = 20\n",
    "test_size = 20\n",
    "\n",
    "df_sig = df.loc[df.isSignal==1, selected_features]\n",
    "df_bkg = df.loc[df.isSignal==0, selected_features]\n",
    "\n",
    "# Extract the samples\n",
    "df_sig_train = df_sig.values[:train_size]\n",
    "df_bkg_train = df_bkg.values[:train_size]\n",
    "df_sig_test = df_sig.values[train_size:train_size + test_size]\n",
    "df_bkg_test = df_bkg.values[train_size:train_size + test_size]\n",
    "# The first train_size events contain SUSY signal and the last train_size events do not.\n",
    "train_data = np.concatenate([df_sig_train, df_bkg_train])\n",
    "# The first test_size events contain SUSY signal and the last test_size events do not.\n",
    "test_data = np.concatenate([df_sig_test, df_bkg_test])\n",
    "\n",
    "# Label\n",
    "train_label = np.zeros(train_size * 2, dtype=int)\n",
    "train_label[:train_size] = 1\n",
    "test_label = np.zeros(train_size * 2, dtype=int)\n",
    "test_label[:test_size] = 1\n",
    "\n",
    "train_label_one_hot = np.zeros((train_size * 2, 2))\n",
    "train_label_one_hot[:train_size, 0] = 1\n",
    "train_label_one_hot[train_size:, 1] = 1\n",
    "test_label_one_hot = np.zeros((test_size * 2, 2))\n",
    "test_label_one_hot[:test_size, 0] = 1\n",
    "test_label_one_hot[test_size:, 1] = 1\n",
    "\n",
    "#datapoints, class_to_label = split_dataset_to_data_and_labels(test_input)\n",
    "#datapoints_tr, class_to_label_tr = split_dataset_to_data_and_labels(training_input)\n",
    "\n",
    "mms = MinMaxScaler((-1, 1))\n",
    "norm_train_data = mms.fit_transform(train_data)\n",
    "norm_test_data = mms.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### State Preparation with Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_map = ZFeatureMap(feature_dimension=feature_dim, reps=1)\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement='circular')\n",
    "feature_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### State Transformation with Variational Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ansatz = TwoLocal(num_qubits=feature_dim, rotation_blocks=['ry', 'rz'], entanglement_blocks='cz', entanglement='circular', reps=3)\n",
    "#ansatz = TwoLocal(num_qubits=feature_dim, rotation_blocks=['ry'], entanglement_blocks='cz', entanglement='circular', reps=3)\n",
    "ansatz.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Measurement and Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Sampler instead of backend\n",
    "sampler = Sampler()\n",
    "\n",
    "maxiter = 300\n",
    "\n",
    "optimizer = COBYLA(maxiter=maxiter, disp=True)\n",
    "\n",
    "objective_func_vals = []\n",
    "# Draw the value of objective function every time when the fit() method is called\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    #print('obj_func_eval =',obj_func_eval)\n",
    "\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(objective_func_vals)\n",
    "    plt.show()\n",
    "\n",
    "vqc = VQC(num_qubits=feature_dim,\n",
    "          feature_map=feature_map,\n",
    "          ansatz=ansatz,\n",
    "          loss=\"cross_entropy\",\n",
    "          optimizer=optimizer,\n",
    "          callback=callback_graph,\n",
    "          sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Execute with Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vqc.fit(norm_train_data, train_label_one_hot)\n",
    "\n",
    "train_score = vqc.score(norm_train_data, train_label_one_hot)\n",
    "test_score = vqc.score(norm_test_data, test_label_one_hot)\n",
    "\n",
    "print(f'--- Classification Train score: {train_score} ---')\n",
    "print(f'--- Classification Test score:  {test_score} ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "## Event Classfication using Quantum Kernel Method\n",
    "\n",
    "Now we try to tackle the same problme with quantum kernel method. First, implement a quantum circuit to encode input data as QuantumCircuit instance. You could use, e.g, ZFeatureMap or ZZFeatureMap as used above or something different.\n",
    "\n",
    "You can change the number of qubits used, but it appears that FidelityQuantumKernel class that we use later will work better if the number of input features is the same as the number of qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement='circular')\n",
    "feature_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next step is to create a quantum circuit to calculate kernel matrix from the feature map defined above. Qiskit has an API (FidelityQuantumKernel class) to do that, and we use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-07T05:34:57.917283Z",
     "start_time": "2024-12-07T05:34:57.908756Z"
    }
   },
   "outputs": [],
   "source": [
    "# FidelityQuantumKernel creates a Sampler instance internally\n",
    "q_kernel = FidelityQuantumKernel(feature_map=feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We try to calculate the fidelity between the two inputs states, $|\\langle0^{\\otimes n}|U_{\\rm{in}}^\\dagger(x_1)U_{\\rm{in}}(x_0)|0^{\\otimes n}\\rangle|^2$, with the FidelityQuantumKernel class. The circuit to do that is obtained by assigning input data to parameters in the feature_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bind_params = dict(zip(feature_map.parameters, norm_train_data[0]))\n",
    "feature_map_0 = feature_map.assign_parameters(bind_params)\n",
    "bind_params = dict(zip(feature_map.parameters, norm_train_data[1]))\n",
    "feature_map_1 = feature_map.assign_parameters(bind_params)\n",
    "\n",
    "qc_circuit = q_kernel.fidelity.create_fidelity_circuit(feature_map_0, feature_map_1)\n",
    "qc_circuit.decompose().decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Execute the circuit with simulator and calculate the probability of measuring 0 in all qubits after applying $U_{\\rm{in}}^\\dagger(x_1)U_{\\rm{in}}(x_0)$ to the input $|0^{\\otimes n}\\rangle$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = Sampler()\n",
    "\n",
    "job = sampler.run(qc_circuit, shots=10000)\n",
    "\n",
    "# quasi_dists[0] is the probability distribution of expected measured counts\n",
    "fidelity = job.result().quasi_dists[0].get(0, 0.)\n",
    "print(f'|<φ(x_1)|φ(x_0)>|^2 = {fidelity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The FidelityQuantumKernel allows us to visualize a kernel matrix obtained from the fidelity calculations. Here we make plots of the kernel matrices calculated from the training data alone, and from the training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "matrix_train = q_kernel.evaluate(x_vec=norm_train_data)\n",
    "matrix_test = q_kernel.evaluate(x_vec=norm_test_data, y_vec=norm_train_data)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(np.asmatrix(matrix_train), interpolation='nearest', origin='upper', cmap='Blues')\n",
    "axs[0].set_title(\"training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(matrix_test), interpolation='nearest', origin='upper', cmap='Reds')\n",
    "axs[1].set_title(\"validation kernel matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, the data are classified into signal and background using support vector machine implemented in sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "qc_svc = SVC(kernel='precomputed') # Default value of hyperparameter (C) is 1\n",
    "qc_svc.fit(matrix_train, train_label)\n",
    "\n",
    "train_score = qc_svc.score(matrix_train, train_label)\n",
    "test_score = qc_svc.score(matrix_test, test_label)\n",
    "\n",
    "print(f'Precomputed kernel: Classification Train score: {train_score*100}%')\n",
    "print(f'Precomputed kernel: Classification Test score:  {test_score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Quantum Machine Learning on Quantum Data\n",
    "\n",
    "We have considered so far a classical ML task with input classical data. Next, we consider a bit more *quantum* ML task, in which quantum computer could be more advantageous than classical computer in the future.\n",
    "\n",
    "What we aim here is a *Hamiltonian learning* task of estimating classical parameters of a given Hamiltonian from quantum states generated under the Hamiltonian. The transverse-field Ising model is considered, and the tasks is to estimate the strength of transverse field by learning VQE-generated ground states using quantum neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's begin VQE using the Ising-model Hamiltonian with varied transverse-field strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qiskit_algorithms.optimizers import SLSQP\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "\n",
    "# VQE setup\n",
    "num_qubits = 2\n",
    "\n",
    "ansatz = TwoLocal(num_qubits, \"ry\", \"cz\", reps=3)  # Ry gates with trainable parameters and CZ for entanglement\n",
    "optimizer = SLSQP(maxiter=1000)  # Classical optimizer\n",
    "ansatz.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Ising model we consider has a parameter `alpha` that controls the mixture of transverse and longitudinal fields. `alpha=0` corresponds to a pure transverse field and `alpha=pi/2` a pure longitudinal field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Estimator\n",
    "estimator = Estimator()\n",
    "vqe = VQE(estimator, ansatz, optimizer)\n",
    "\n",
    "# Ising model Hamiltonian with transverse and longitudinal fields\n",
    "def get_hamiltonian(L, J, h, alpha=0):\n",
    "\n",
    "    # List of Hamiltonian terms as 3-tuples containing\n",
    "    # (1) the Pauli string,\n",
    "    # (2) the qubit indices corresponding to the Pauli string,\n",
    "    # (3) the coefficient.\n",
    "    ZZ_tuples = [(\"ZZ\", [i, i + 1], -J) for i in range(0, L - 1)]\n",
    "    Z_tuples = [(\"Z\", [i], -h * np.sin(alpha)) for i in range(0, L)]\n",
    "    X_tuples = [(\"X\", [i], -h * np.cos(alpha)) for i in range(0, L)]\n",
    "\n",
    "    # We create the Hamiltonian as a SparsePauliOp, via the method\n",
    "    # `from_sparse_list`, and multiply by the interaction term.\n",
    "    hamiltonian = SparsePauliOp.from_sparse_list([*ZZ_tuples, *Z_tuples, *X_tuples], num_qubits=L)\n",
    "    return hamiltonian.simplify()\n",
    "\n",
    "# Example:\n",
    "J = 0.2\n",
    "h = 1.2\n",
    "alpha = np.pi/8\n",
    "H = get_hamiltonian(L=num_qubits, J=J, h=h, alpha=alpha)\n",
    "\n",
    "result = vqe.compute_minimum_eigenvalue(H)\n",
    "#print(result)\n",
    "print(f'VQE energy value = {result.optimal_value:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since the system is small, the exact ground state energy can be calcualted by diagonalizing the Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy_solver = NumPyMinimumEigensolver()\n",
    "result = numpy_solver.compute_minimum_eigenvalue(operator=H)\n",
    "ref_value = result.eigenvalue.real\n",
    "print(f\"Reference energy value = {ref_value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OK, now create a dataset of VQE ground states with different `h` values. For simplicity, the `alpha` parameter is set to 0 and only the transverse field is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit_machine_learning.algorithms import NeuralNetworkRegressor\n",
    "\n",
    "Nexp = 10   # number of experiments\n",
    "Ntrain = 20  # number of training data per experiment\n",
    "Ntest = 5\n",
    "J = 0.2\n",
    "alpha = 0\n",
    "\n",
    "h_list = [np.random.rand()*0.25 for _ in range(Ntrain)]\n",
    "#h_list = [np.random.rand() for _ in range(Ntrain)]\n",
    "print(f'Input field strenghs = {h_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vqe_ansatz = TwoLocal(num_qubits, \"ry\", \"cz\", parameter_prefix='x')\n",
    "optimizer = SLSQP(maxiter=1000)\n",
    "\n",
    "estimator = Estimator()\n",
    "vqe = VQE(estimator, vqe_ansatz, optimizer)\n",
    "\n",
    "opt_vqe_energy = []\n",
    "opt_vqe_params = []\n",
    "for i in range(Ntrain):\n",
    "    H = get_hamiltonian(L=num_qubits, J=J, h=h_list[i], alpha=alpha)\n",
    "    result_vqe = vqe.compute_minimum_eigenvalue(H)\n",
    "    opt_vqe_energy.append(result_vqe.optimal_value)\n",
    "    opt_vqe_params.append(list(result_vqe.optimal_parameters.values()))\n",
    "    print('VQE i =',i)\n",
    "\n",
    "for i in range(Ntrain):\n",
    "    print(f'VQE[{i}] energy value = {opt_vqe_energy[i]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sanity check with exact diagonalizatiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy_solver = NumPyMinimumEigensolver()\n",
    "for i in range(Ntrain):\n",
    "    H = get_hamiltonian(L=num_qubits, J=J, h=h_list[i], alpha=alpha)\n",
    "    result = numpy_solver.compute_minimum_eigenvalue(operator=H)\n",
    "    ref_value = result.eigenvalue.real\n",
    "    print(f\"Reference[{i}] energy value = {ref_value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now construct a quantum circuit with the optimized VQE circuit for generating ground states at the beginning and a QNN ansatz for learning the state at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "\n",
    "# Observable : Pauli Z for the first qubit\n",
    "pauli = 'I' * (num_qubits - 1)\n",
    "pauli += 'Z'\n",
    "obs = SparsePauliOp([pauli],coeffs=2.)\n",
    "\n",
    "# Callback function to store loss values\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "\n",
    "# QNN setup with RealAmplitudes ansatz\n",
    "nlayer = 3  # number of CX-RY layers\n",
    "\n",
    "result_exp = []\n",
    "regressor_exp = []\n",
    "objective_func_vals_exp = []\n",
    "\n",
    "# Repeat Nexp times\n",
    "for iexp in range(Nexp):\n",
    "\n",
    "    qnn_ansatz = RealAmplitudes(num_qubits=num_qubits, reps=nlayer, parameter_prefix='theta')\n",
    "\n",
    "    '''\n",
    "    qnn_ansatz = QuantumCircuit(num_qubits)\n",
    "    theta = ParameterVector('theta')\n",
    "    def new_theta():\n",
    "        theta.resize(len(theta) + 1)\n",
    "        return theta[-1]\n",
    "    for il in range(0, nlayer):\n",
    "        for i in range(0, num_qubits-1):\n",
    "            qnn_ansatz.rzz(new_theta(),i,i+1)\n",
    "        for i in range(0, num_qubits):\n",
    "            qnn_ansatz.rx(new_theta(),i)\n",
    "    '''\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.compose(vqe_ansatz, inplace=True)\n",
    "    qc.compose(qnn_ansatz, inplace=True)\n",
    "\n",
    "    # Random initial parameters within [0, pi]\n",
    "    initial_weights = np.random.rand((nlayer+1)*num_qubits)*np.pi\n",
    "    #initial_weights = np.random.rand((2*num_qubits-1)*nlayer)*np.pi\n",
    "\n",
    "    # Use EstimatorQNN class\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit = qc,\n",
    "        input_params = vqe_ansatz.parameters,\n",
    "        weight_params = qnn_ansatz.parameters,\n",
    "        observables = obs\n",
    "    )\n",
    "\n",
    "    # Use NeuralNetworkRegressor for regression task with COBYLA optimizer\n",
    "    regressor = NeuralNetworkRegressor(\n",
    "        neural_network = qnn,\n",
    "        loss = \"squared_error\",\n",
    "        optimizer = SLSQP(maxiter=1000),\n",
    "        warm_start = True,\n",
    "        initial_point = initial_weights,\n",
    "        callback = callback_graph\n",
    "    )\n",
    "\n",
    "    objective_func_vals = []\n",
    "    result_regres = regressor.fit(np.array(opt_vqe_params),np.array(h_list))\n",
    "    result_exp.append(result_regres)\n",
    "    regressor_exp.append(regressor)\n",
    "    objective_func_vals_exp.append(objective_func_vals)\n",
    "\n",
    "    print(f'iexp = {iexp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make the plot of loss function values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor=\"w\")\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.title('Objective function value against iteration')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective function value\")\n",
    "for iexp in range(Nexp):\n",
    "    plt.plot(range(len(objective_func_vals_exp[iexp])), objective_func_vals_exp[iexp])\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "See the correlation between the true and predicted transverse-field strengths from the optimized QNN model. The plot shows only the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pred_exp = []\n",
    "for iexp in range(Nexp):\n",
    "    train_pred = regressor_exp[iexp].predict(np.array(opt_vqe_params))\n",
    "    train_pred_exp.append(train_pred)\n",
    "    plt.scatter(h_list, train_pred, label='training')\n",
    "plt.title('True vs Predicted values')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.xlim(-0.05,0.3)\n",
    "plt.ylim(-0.15,0.35)\n",
    "plt.plot([-0.2,1.2],[-0.2,1.2],'k--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
